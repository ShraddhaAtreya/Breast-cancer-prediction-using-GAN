{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_LC4sfnWlL",
        "outputId": "ee14e8b2-8568-47de-eeb0-22d1d37715d6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install pandas numpy scikit-learn imbalanced-learn mlxtend tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, Input\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORRECTED CODE**"
      ],
      "metadata": {
        "id": "h1xyVdWx60h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth enabled.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NUwN6bTAHSb",
        "outputId": "c9dc2369-cdf9-4fa4-8c1c-9f493e38c95c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU detected. Running on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "print(\"Dataset loaded successfully. Shape:\", data.shape)\n",
        "\n",
        "# Handle Missing Values\n",
        "print(\"Handling missing values...\")\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "print(\"Missing values filled.\")\n",
        "\n",
        "# Encode Target Variable\n",
        "print(\"Encoding target variable...\")\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])\n",
        "print(\"Target variable encoded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVjjYP3fAMGW",
        "outputId": "495dfa6a-fa2b-4552-e289-adb0afc7bcf3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded successfully. Shape: (286, 10)\n",
            "Handling missing values...\n",
            "Missing values filled.\n",
            "Encoding target variable...\n",
            "Target variable encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "print(\"Feature encoding completed. Shape:\", X_encoded.shape)\n",
        "\n",
        "# Balance Dataset using SMOTE\n",
        "print(\"Applying SMOTE for data balancing...\")\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_encoded, y)\n",
        "print(\"SMOTE applied. Balanced dataset shape:\", X_smote.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pkYfmFHAQQ1",
        "outputId": "eff8a63e-b808-4fef-9db5-4e3ba90b686c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature encoding completed. Shape: (286, 41)\n",
            "Applying SMOTE for data balancing...\n",
            "SMOTE applied. Balanced dataset shape: (402, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "print(\"Building GAN models...\")\n",
        "generator = build_generator(X_smote.shape[1], X_smote.shape[1])\n",
        "discriminator = build_discriminator(X_smote.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"GAN models built successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkpJHazjC2ZA",
        "outputId": "0b2a0c1b-aea6-4b2e-9133-f97aa59ffbf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building GAN models...\n",
            "GAN models built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(epochs=1000, batch_size=8):  # Reduced batch size for memory efficiency\n",
        "    tf.keras.backend.clear_session()  # Reset session before training\n",
        "    print(\"Starting GAN training...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, X_smote.shape[1]))\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_indices = np.random.randint(0, X_smote.shape[0], batch_size)\n",
        "        real_data = X_smote.iloc[real_indices].values.astype(np.float32)  # Ensure TensorFlow compatible format\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, labels_fake)\n",
        "\n",
        "        gan_loss = discriminator.train_on_batch(generated_data, labels_real)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, GAN Loss: {gan_loss}\")\n",
        "\n",
        "print(\"Training GAN...\")\n",
        "train_gan()\n",
        "print(\"GAN training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzfIKre3AU0c",
        "outputId": "ff8a7d37-7b18-4217-b754-cd37cf3e821a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GAN...\n",
            "Starting GAN training...\n",
            "Epoch 0: D Loss Real: 0.6460530757904053, D Loss Fake: 0.7137609720230103, GAN Loss: [array(0.6901722, dtype=float32), array(0.5833333, dtype=float32)]\n",
            "Epoch 100: D Loss Real: 0.49100086092948914, D Loss Fake: 0.4916430413722992, GAN Loss: [array(0.49239215, dtype=float32), array(0.6563531, dtype=float32)]\n",
            "Epoch 200: D Loss Real: 0.4809909462928772, D Loss Fake: 0.4813328683376312, GAN Loss: [array(0.4817236, dtype=float32), array(0.65588725, dtype=float32)]\n",
            "Epoch 300: D Loss Real: 0.47655606269836426, D Loss Fake: 0.4768238961696625, GAN Loss: [array(0.4770474, dtype=float32), array(0.65614617, dtype=float32)]\n",
            "Epoch 400: D Loss Real: 0.4740772843360901, D Loss Fake: 0.47426488995552063, GAN Loss: [array(0.47444808, dtype=float32), array(0.6557564, dtype=float32)]\n",
            "Epoch 500: D Loss Real: 0.47233477234840393, D Loss Fake: 0.4724773168563843, GAN Loss: [array(0.47263187, dtype=float32), array(0.65568864, dtype=float32)]\n",
            "Epoch 600: D Loss Real: 0.47109898924827576, D Loss Fake: 0.4712251126766205, GAN Loss: [array(0.47134802, dtype=float32), array(0.6555047, dtype=float32)]\n",
            "Epoch 700: D Loss Real: 0.4701727032661438, D Loss Fake: 0.4702838957309723, GAN Loss: [array(0.47038776, dtype=float32), array(0.65561104, dtype=float32)]\n",
            "Epoch 800: D Loss Real: 0.46944358944892883, D Loss Fake: 0.4695518910884857, GAN Loss: [array(0.46963346, dtype=float32), array(0.65496254, dtype=float32)]\n",
            "Epoch 900: D Loss Real: 0.46885615587234497, D Loss Fake: 0.46893712878227234, GAN Loss: [array(0.46902326, dtype=float32), array(0.6547817, dtype=float32)]\n",
            "GAN training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Performing Association Rule Mining using Apriori algorithm...\")\n",
        "\n",
        "data_apriori = X_smote.astype(bool)  # Convert to True/False (1/0)\n",
        "\n",
        "frequent_itemsets = apriori(data_apriori, min_support=0.15, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.75)\n",
        "\n",
        "print(\"Association Rule Mining completed. Rules found:\", rules.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyg22dv_Aa8t",
        "outputId": "aff2bcb6-cce5-480a-b552-b36c0abcfc95"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing Association Rule Mining using Apriori algorithm...\n",
            "Association Rule Mining completed. Rules found: 388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Random Forest Classifier with GridSearchCV...\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_ziM47Adg7",
        "outputId": "c55de797-7e79-4838-e70e-0a680369bb10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier with GridSearchCV...\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82        41\n",
            "           1       0.84      0.78      0.81        40\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.82      0.81      0.81        81\n",
            "weighted avg       0.82      0.81      0.81        81\n",
            "\n",
            "ROC-AUC Score: 0.9030487804878049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Cancer Detected\" if prediction[0] == 1 else \"No Cancer Detected\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    print(\"Prediction:\", result, \"| Confidence:\", confidence)\n",
        "    return result, confidence\n"
      ],
      "metadata": {
        "id": "09ngXo-fAheK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE INPUTS"
      ],
      "metadata": {
        "id": "0QCXsS-m9YNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "example_input = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMfQn98q-UVt",
        "outputId": "ea5373b0-5b37-4bd5-dd5b-d7b40e8ae4af"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected | Confidence: 0.30892742021745634\n",
            "Prediction: No Cancer Detected, Confidence: 0.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '50-54', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'right', 'Breast-quad': 'right_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OajJG4tF1MUq",
        "outputId": "722459e6-2e20-497f-a50f-5571c7886aee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected | Confidence: 0.812765444015444\n",
            "Prediction: Cancer Detected, Confidence: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '60-69', 'Menopause': 'ge-40', 'Tumor-size': '15-19', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "#60-69,ge40,15-19,0-2,no,2,right,left_up,no\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQEgIbUG8KnM",
        "outputId": "6647ceaf-dcab-4ff0-a959-b8b14491d06c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected | Confidence: 0.21254086798890662\n",
            "Prediction: No Cancer Detected, Confidence: 0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '20-24', 'Inv-nodes': '3-5',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 2,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "#30-39,premeno,20-24,3-5,yes,2,left,left_low,no\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXoFmT0y8Myl",
        "outputId": "0aafe5ee-8572-4f6b-d9d0-368fd9951cbf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected | Confidence: 0.7175413678379087\n",
            "Prediction: Cancer Detected, Confidence: 0.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30-39,premeno,0-4,0-2,no,2,right,central,no\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '0-4', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'central', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "id": "gVSXbMYP81dF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e351e17b-36fb-4460-a771-f8890d27a7e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected | Confidence: 0.4068955988071309\n",
            "Prediction: No Cancer Detected, Confidence: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#50-59,ge40,40-44,6-8,yes,3,left,left_low,yes\n",
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '40-44', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbhyWrpoAnjw",
        "outputId": "ff4b6bff-037a-4b4f-83bb-93620ca899a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected | Confidence: 0.951515444015444\n",
            "Prediction: Cancer Detected, Confidence: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FULL CODE**"
      ],
      "metadata": {
        "id": "4v9Cc6n8AnJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Handle Missing Values\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "\n",
        "# Encode Target Variable\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])  # Encode target variable\n",
        "\n",
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Balance Dataset using SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_smote, y_smote = smote.fit_resample(X_encoded, y)\n",
        "\n",
        "# GAN for Data Augmentation\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "generator = build_generator(X_smote.shape[1], X_smote.shape[1])\n",
        "discriminator = build_discriminator(X_smote.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train GAN with TensorFlow context\n",
        "def train_gan(epochs=800, batch_size=8):  # Reduced batch size for memory efficiency\n",
        "    tf.keras.backend.clear_session()  # Reset session before training\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, X_smote.shape[1]))\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_indices = np.random.randint(0, X_smote.shape[0], batch_size)\n",
        "        real_data = X_smote.iloc[real_indices].values.astype(np.float32)  # Ensure TensorFlow compatible format\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, labels_fake)\n",
        "\n",
        "        gan_loss = discriminator.train_on_batch(generated_data, labels_real)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, GAN Loss: {gan_loss}\")\n",
        "\n",
        "train_gan()\n",
        "\n",
        "# Association Rule Mining with Apriori\n",
        "data_apriori = X_smote.astype(bool)  # Convert to True/False (1/0)\n",
        "\n",
        "frequent_itemsets = apriori(data_apriori, min_support=0.15, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.75)\n",
        "\n",
        "# Enhanced Classification Model with Random Forest & Grid Search\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# Prediction Function\n",
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Cancer Detected\" if prediction[0] == 1 else \"No Cancer Detected\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    return result, confidence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85vImWBArbw",
        "outputId": "5658835f-18ae-4f43-9cf2-ba8004f90ca2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: D Loss Real: 0.5645670890808105, D Loss Fake: 0.6543660759925842, GAN Loss: [array(0.661758, dtype=float32), array(0.5833333, dtype=float32)]\n",
            "Epoch 100: D Loss Real: 0.480855792760849, D Loss Fake: 0.48154687881469727, GAN Loss: [array(0.48227942, dtype=float32), array(0.65470296, dtype=float32)]\n",
            "Epoch 200: D Loss Real: 0.4741106927394867, D Loss Fake: 0.4744380712509155, GAN Loss: [array(0.47485518, dtype=float32), array(0.65526533, dtype=float32)]\n",
            "Epoch 300: D Loss Real: 0.4712628126144409, D Loss Fake: 0.471564918756485, GAN Loss: [array(0.47176713, dtype=float32), array(0.6551772, dtype=float32)]\n",
            "Epoch 400: D Loss Real: 0.4696388840675354, D Loss Fake: 0.46982988715171814, GAN Loss: [array(0.47001478, dtype=float32), array(0.65544474, dtype=float32)]\n",
            "Epoch 500: D Loss Real: 0.46857750415802, D Loss Fake: 0.4687296152114868, GAN Loss: [array(0.46888095, dtype=float32), array(0.6552728, dtype=float32)]\n",
            "Epoch 600: D Loss Real: 0.46783554553985596, D Loss Fake: 0.46797293424606323, GAN Loss: [array(0.46808898, dtype=float32), array(0.65439546, dtype=float32)]\n",
            "Epoch 700: D Loss Real: 0.46727174520492554, D Loss Fake: 0.46738582849502563, GAN Loss: [array(0.46748912, dtype=float32), array(0.65353066, dtype=float32)]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.82        41\n",
            "           1       0.81      0.85      0.83        40\n",
            "\n",
            "    accuracy                           0.83        81\n",
            "   macro avg       0.83      0.83      0.83        81\n",
            "weighted avg       0.83      0.83      0.83        81\n",
            "\n",
            "ROC-AUC Score: 0.9338414634146343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30-39,premeno,0-4,0-2,no,2,right,central,no\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '0-4', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'central', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWf3V1XBAsLA",
        "outputId": "5bf20b04-2cff-4f2f-c030-dd953700e380"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected, Confidence: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#50-59,ge40,40-44,6-8,yes,3,left,left_low,yes\n",
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '40-44', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Y3cWdTBGg3",
        "outputId": "0653f8a5-3d70-4d4d-e571-710227da0582"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected, Confidence: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "recurrent and non-recurrent\n"
      ],
      "metadata": {
        "id": "Kyx5lxW0LpDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from imblearn.combine import SMOTETomek\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Handle Missing Values\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "\n",
        "# Encode Target Variable for Recurrent vs. Non-Recurrent Classification\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])  # 0: Non-Recurrent, 1: Recurrent\n",
        "\n",
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Balance Dataset using SMOTETomek\n",
        "smote_tomek = SMOTETomek(sampling_strategy='auto')\n",
        "X_smote, y_smote = smote_tomek.fit_resample(X_encoded, y)\n",
        "\n",
        "# Enhanced Classification Model with Random Forest & Grid Search\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200, 300], 'classifier__max_depth': [10, 20, 30]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=10, scoring='f1', n_jobs=-1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# Prediction Function\n",
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Recurrent Breast Cancer\" if prediction[0] == 1 else \"Non-Recurrent Breast Cancer\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    return result, confidence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk1I9ci8LrnN",
        "outputId": "4151fc56-657b-4612-fac5-3aaa35ac39dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82        40\n",
            "           1       0.82      0.82      0.82        40\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.82      0.82      0.82        80\n",
            "weighted avg       0.82      0.82      0.82        80\n",
            "\n",
            "ROC-AUC Score: 0.9099999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Non-Recurrent Case\n",
        "example_input_1 = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "# Example: Recurrent Case\n",
        "example_input_2 = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '50-54', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3, 'Breast': 'right', 'Breast-quad': 'right_up', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "# Making Predictions\n",
        "result_1, confidence_1 = predict_cancer(example_input_1)\n",
        "print(f\"Prediction: {result_1}, Confidence: {confidence_1:.2f}\")\n",
        "\n",
        "result_2, confidence_2 = predict_cancer(example_input_2)\n",
        "print(f\"Prediction: {result_2}, Confidence: {confidence_2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fhy_EjqL2ud",
        "outputId": "4576f20a-ffe3-4f93-f228-5198456b5901"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Non-Recurrent Breast Cancer, Confidence: 0.18\n",
            "Prediction: Recurrent Breast Cancer, Confidence: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#no-recurrence-events,60-69,ge40,30-34,0-2,no,2,left,left_low,yes\n",
        "example_input_3 = {\n",
        "    'Age': '60-69', 'Menopause': 'ge40', 'Tumor-size': '30-34', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "# Making Predictions\n",
        "result_1, confidence_1 = predict_cancer(example_input_1)\n",
        "print(f\"Prediction: {result_1}, Confidence: {confidence_1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEOncxnWMDXD",
        "outputId": "32ebb79f-8378-4e43-c251-b60e0868122a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Non-Recurrent Breast Cancer, Confidence: 0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recurrence-events,40-49,premeno,30-34,3-5,no,2,right,left_up,no\n",
        "\n",
        "example_input_4 = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34', 'Inv-nodes': '3-5',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'right', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "# Making Predictions\n",
        "result_1, confidence_1 = predict_cancer(example_input_4)\n",
        "print(f\"Prediction: {result_1}, Confidence: {confidence_1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dCSn8dTMb2Y",
        "outputId": "70f9f3ed-d4c6-44c2-df58-7272b8e01766"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Recurrent Breast Cancer, Confidence: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recurrence-events,30-39,premeno,40-44,0-2,no,1,left,left_up,no\n",
        "\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '40-44', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 1,'Breast': 'left', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQFaZwxONXQG",
        "outputId": "fecaeab6-03cd-45d2-b120-1b560bcd3f7d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Recurrent Breast Cancer, Confidence: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAYKsu99Ntm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}