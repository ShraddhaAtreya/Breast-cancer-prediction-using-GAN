{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_LC4sfnWlL",
        "outputId": "70d4829f-ee05-4b55-f8e7-231c349740da",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install pandas numpy scikit-learn imbalanced-learn mlxtend tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, Input\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORRECTED CODE**"
      ],
      "metadata": {
        "id": "h1xyVdWx60h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth enabled.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NUwN6bTAHSb",
        "outputId": "9ec8cc9f-bb5a-45c9-8366-c29aaaf6ae6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU detected. Running on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "print(\"Dataset loaded successfully. Shape:\", data.shape)\n",
        "\n",
        "# Handle Missing Values\n",
        "print(\"Handling missing values...\")\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "print(\"Missing values filled.\")\n",
        "\n",
        "# Encode Target Variable\n",
        "print(\"Encoding target variable...\")\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])\n",
        "print(\"Target variable encoded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVjjYP3fAMGW",
        "outputId": "d0ba3ab2-6219-4f9f-a793-7700d208d3b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded successfully. Shape: (286, 10)\n",
            "Handling missing values...\n",
            "Missing values filled.\n",
            "Encoding target variable...\n",
            "Target variable encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "print(\"Feature encoding completed. Shape:\", X_encoded.shape)\n",
        "\n",
        "# Balance Dataset using SMOTE\n",
        "print(\"Applying SMOTE for data balancing...\")\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_encoded, y)\n",
        "print(\"SMOTE applied. Balanced dataset shape:\", X_smote.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pkYfmFHAQQ1",
        "outputId": "dff869e7-fa9b-4cb6-d618-af22484c2312"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature encoding completed. Shape: (286, 41)\n",
            "Applying SMOTE for data balancing...\n",
            "SMOTE applied. Balanced dataset shape: (402, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "print(\"Building GAN models...\")\n",
        "generator = build_generator(X_smote.shape[1], X_smote.shape[1])\n",
        "discriminator = build_discriminator(X_smote.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"GAN models built successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkpJHazjC2ZA",
        "outputId": "e70aa1f7-d760-4899-f81b-99a8e91a4cdc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building GAN models...\n",
            "GAN models built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(epochs=1000, batch_size=8):  # Reduced batch size for memory efficiency\n",
        "    tf.keras.backend.clear_session()  # Reset session before training\n",
        "    print(\"Starting GAN training...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, X_smote.shape[1]))\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_indices = np.random.randint(0, X_smote.shape[0], batch_size)\n",
        "        real_data = X_smote.iloc[real_indices].values.astype(np.float32)  # Ensure TensorFlow compatible format\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, labels_fake)\n",
        "\n",
        "        gan_loss = discriminator.train_on_batch(generated_data, labels_real)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, GAN Loss: {gan_loss}\")\n",
        "\n",
        "print(\"Training GAN...\")\n",
        "train_gan()\n",
        "print(\"GAN training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzfIKre3AU0c",
        "outputId": "a438bb0a-0ebd-4674-dccc-3ad0a612e168"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GAN...\n",
            "Starting GAN training...\n",
            "Epoch 0: D Loss Real: 0.4671197235584259, D Loss Fake: 0.4671938419342041, GAN Loss: [array(0.46727142, dtype=float32), array(0.64685315, dtype=float32)]\n",
            "Epoch 100: D Loss Real: 0.4668023884296417, D Loss Fake: 0.4668732285499573, GAN Loss: [array(0.4669408, dtype=float32), array(0.6459658, dtype=float32)]\n",
            "Epoch 200: D Loss Real: 0.46654775738716125, D Loss Fake: 0.4666108191013336, GAN Loss: [array(0.46667457, dtype=float32), array(0.64550376, dtype=float32)]\n",
            "Epoch 300: D Loss Real: 0.4663275480270386, D Loss Fake: 0.4663861095905304, GAN Loss: [array(0.4664448, dtype=float32), array(0.6446964, dtype=float32)]\n",
            "Epoch 400: D Loss Real: 0.46612340211868286, D Loss Fake: 0.46617716550827026, GAN Loss: [array(0.46623224, dtype=float32), array(0.6442125, dtype=float32)]\n",
            "Epoch 500: D Loss Real: 0.46594491600990295, D Loss Fake: 0.46599650382995605, GAN Loss: [array(0.46604678, dtype=float32), array(0.64382076, dtype=float32)]\n",
            "Epoch 600: D Loss Real: 0.46580764651298523, D Loss Fake: 0.46585813164711, GAN Loss: [array(0.46590307, dtype=float32), array(0.6437123, dtype=float32)]\n",
            "Epoch 700: D Loss Real: 0.46566247940063477, D Loss Fake: 0.46570849418640137, GAN Loss: [array(0.46575227, dtype=float32), array(0.6429796, dtype=float32)]\n",
            "Epoch 800: D Loss Real: 0.4655342698097229, D Loss Fake: 0.4655773341655731, GAN Loss: [array(0.46561915, dtype=float32), array(0.6427448, dtype=float32)]\n",
            "Epoch 900: D Loss Real: 0.4654143750667572, D Loss Fake: 0.4654560685157776, GAN Loss: [array(0.46549478, dtype=float32), array(0.64255655, dtype=float32)]\n",
            "GAN training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Performing Association Rule Mining using Apriori algorithm...\")\n",
        "\n",
        "data_apriori = X_smote.astype(bool)  # Convert to True/False (1/0)\n",
        "\n",
        "frequent_itemsets = apriori(data_apriori, min_support=0.15, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.75)\n",
        "\n",
        "print(\"Association Rule Mining completed. Rules found:\", rules.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyg22dv_Aa8t",
        "outputId": "b2fd3d05-231e-4ce0-e137-a93f8505b00a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing Association Rule Mining using Apriori algorithm...\n",
            "Association Rule Mining completed. Rules found: 388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Random Forest Classifier with GridSearchCV...\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_ziM47Adg7",
        "outputId": "4c2007ba-abf5-481b-c6cd-607ec5441359"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier with GridSearchCV...\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82        41\n",
            "           1       0.84      0.78      0.81        40\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.82      0.81      0.81        81\n",
            "weighted avg       0.82      0.81      0.81        81\n",
            "\n",
            "ROC-AUC Score: 0.9030487804878049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Cancer Detected\" if prediction[0] == 1 else \"No Cancer Detected\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    print(\"Prediction:\", result, \"| Confidence:\", confidence)\n",
        "    return result, confidence\n"
      ],
      "metadata": {
        "id": "09ngXo-fAheK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE INPUTS"
      ],
      "metadata": {
        "id": "0QCXsS-m9YNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "example_input = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMfQn98q-UVt",
        "outputId": "919a88b8-79f2-4143-dfc9-d0611ac7d1df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected, Confidence: 0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '50-54', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'right', 'Breast-quad': 'right_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OajJG4tF1MUq",
        "outputId": "87a45e92-6b82-4252-ecc5-9e0097044485"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected, Confidence: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '60-69', 'Menopause': 'ge-40', 'Tumor-size': '15-19', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "#60-69,ge40,15-19,0-2,no,2,right,left_up,no\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQEgIbUG8KnM",
        "outputId": "3df4f287-f847-4ddf-cb12-9b26cc72205f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected, Confidence: 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '20-24', 'Inv-nodes': '3-5',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 2,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "#30-39,premeno,20-24,3-5,yes,2,left,left_low,no\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXoFmT0y8Myl",
        "outputId": "101bf30b-ac5c-4cc0-f4c9-e244c192aba0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected, Confidence: 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30-39,premeno,0-4,0-2,no,2,right,central,no\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '0-4', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'central', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "id": "gVSXbMYP81dF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5388c52e-aac7-4a41-9018-95a55869b75a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected, Confidence: 0.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#50-59,ge40,40-44,6-8,yes,3,left,left_low,yes\n",
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '40-44', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbhyWrpoAnjw",
        "outputId": "d91c5a1b-1bc8-49f0-e75b-1df0c40a04e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected, Confidence: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FULL CODE**"
      ],
      "metadata": {
        "id": "4v9Cc6n8AnJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Handle Missing Values\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "\n",
        "# Encode Target Variable\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])  # Encode target variable\n",
        "\n",
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Balance Dataset using SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_smote, y_smote = smote.fit_resample(X_encoded, y)\n",
        "\n",
        "# GAN for Data Augmentation\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "generator = build_generator(X_smote.shape[1], X_smote.shape[1])\n",
        "discriminator = build_discriminator(X_smote.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train GAN with TensorFlow context\n",
        "def train_gan(epochs=800, batch_size=8):  # Reduced batch size for memory efficiency\n",
        "    tf.keras.backend.clear_session()  # Reset session before training\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, X_smote.shape[1]))\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_indices = np.random.randint(0, X_smote.shape[0], batch_size)\n",
        "        real_data = X_smote.iloc[real_indices].values.astype(np.float32)  # Ensure TensorFlow compatible format\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, labels_fake)\n",
        "\n",
        "        gan_loss = discriminator.train_on_batch(generated_data, labels_real)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, GAN Loss: {gan_loss}\")\n",
        "\n",
        "train_gan()\n",
        "\n",
        "# Association Rule Mining with Apriori\n",
        "data_apriori = X_smote.astype(bool)  # Convert to True/False (1/0)\n",
        "\n",
        "frequent_itemsets = apriori(data_apriori, min_support=0.15, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.75)\n",
        "\n",
        "# Enhanced Classification Model with Random Forest & Grid Search\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# Prediction Function\n",
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Cancer Detected\" if prediction[0] == 1 else \"No Cancer Detected\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    return result, confidence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85vImWBArbw",
        "outputId": "fc915873-32bd-4b5b-809c-69c74a032c23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: D Loss Real: 0.5779613256454468, D Loss Fake: 0.7260609865188599, GAN Loss: [array(0.67304164, dtype=float32), array(0.625, dtype=float32)]\n",
            "Epoch 100: D Loss Real: 0.4992862343788147, D Loss Fake: 0.5000479817390442, GAN Loss: [array(0.5006745, dtype=float32), array(0.6596535, dtype=float32)]\n",
            "Epoch 200: D Loss Real: 0.4856933057308197, D Loss Fake: 0.48616713285446167, GAN Loss: [array(0.48642698, dtype=float32), array(0.65941125, dtype=float32)]\n",
            "Epoch 300: D Loss Real: 0.4797906279563904, D Loss Fake: 0.4801153838634491, GAN Loss: [array(0.48028228, dtype=float32), array(0.6576689, dtype=float32)]\n",
            "Epoch 400: D Loss Real: 0.4764377474784851, D Loss Fake: 0.476627916097641, GAN Loss: [array(0.47680196, dtype=float32), array(0.6577307, dtype=float32)]\n",
            "Epoch 500: D Loss Real: 0.47430968284606934, D Loss Fake: 0.47446316480636597, GAN Loss: [array(0.4746049, dtype=float32), array(0.6566866, dtype=float32)]\n",
            "Epoch 600: D Loss Real: 0.4728017747402191, D Loss Fake: 0.47294291853904724, GAN Loss: [array(0.47305164, dtype=float32), array(0.65585136, dtype=float32)]\n",
            "Epoch 700: D Loss Real: 0.4716792106628418, D Loss Fake: 0.4717836380004883, GAN Loss: [array(0.4718943, dtype=float32), array(0.6547195, dtype=float32)]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83        41\n",
            "           1       0.84      0.80      0.82        40\n",
            "\n",
            "    accuracy                           0.83        81\n",
            "   macro avg       0.83      0.83      0.83        81\n",
            "weighted avg       0.83      0.83      0.83        81\n",
            "\n",
            "ROC-AUC Score: 0.8902439024390243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30-39,premeno,0-4,0-2,no,2,right,central,no\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '0-4', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'central', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWf3V1XBAsLA",
        "outputId": "ddff79f1-8e31-4176-e95a-93e543d96c9b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected, Confidence: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#50-59,ge40,40-44,6-8,yes,3,left,left_low,yes\n",
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '40-44', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Y3cWdTBGg3",
        "outputId": "1af90084-d333-4ef3-e435-952bf3b5498b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected, Confidence: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qXH9AgaECTsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}